---
output:
  html_document: default
  pdf_document: default
---
####### PREDICT IF TRANSACTION IS BY LOYAL CUSTOMERS IN MACHINE LEARNING USING R ######
####### BY BRIAN ESTVANDER DATE: 10 MAY 2024 #####

```{r}
# Load libraries and read in data----

library(tidyverse)
df1 <- read_rds('logistic1.rds')
```

```{r}
# Build a Matrix Function to be used later----

my_confusion_matrix <- function(cf_table) {
  true_positive <- cf_table[4]
  true_negative <- cf_table[1]
  false_positive <- cf_table[2]
  false_negative <- cf_table[3]
  accuracy <- (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)
  sensitivity_recall <- true_positive / (true_positive + false_negative) 
  specificity_selectivity <- true_negative / (true_negative + false_positive)
  precision <- true_positive / (true_positive + false_positive) 
  neg_pred_value <- true_negative/(true_negative + false_negative)
  print(cf_table)
  my_list <- list(sprintf("%1.0f = True Positive (TP), Hit", true_positive),
                  sprintf("%1.0f = True Negative (TN), Rejection", true_negative),
                  sprintf("%1.0f = False Positive (FP), Type 1 Error", false_positive),
                  sprintf("%1.0f = False Negative (FN), Type 2 Error", false_negative),
                  sprintf("%1.4f = Accuracy (TP+TN/(TP+TN+FP+FN))", accuracy), 
                  sprintf("%1.4f = Sensitivity, Recall, Hit Rate, True Positive Rate (How many positives did the model get right? TP/(TP+FN))", sensitivity_recall),
                  sprintf("%1.4f = Specificity, Selectivity, True Negative Rate (How many negatives did the model get right? TN/(TN+FP))", specificity_selectivity),                   
                  sprintf("%1.4f = Precision, Positive Predictive Value (How good are the model's positive predictions? TP/(TP+FP))", precision),
                  sprintf("%1.4f = Negative Predictive Value (How good are the model's negative predictions? TN/(TN+FN)", neg_pred_value)
  )
  return(my_list)
}
```

# Start with linear regression (sigmoidial) as first classification model then try RELU----

```{r}
# View the data----
slice_sample(df1, n=10)
```
# Baseline Occurance of 'loyality'

```{r}
loyal_table <- table(df1$loyalty)
print(loyal_table)
print(loyal_table[2]/(loyal_table[1]+loyal_table[2]))
```
# Use contrast() to check order of 'loyality'----

```{r}
contrasts(df1$loyalty)
```
# Order is good so now split the data to get ~ 75% as training data----
# Also, load caret library----
```{r}
library(caret)
set.seed(77) 
partition <- caret::createDataPartition(y=df1$loyalty, p=.75, list=FALSE) 
data_train <- df1[partition,]
data_test <- df1[-partition,]
print(nrow(data_train)/(nrow(data_test)+nrow(data_train)))
```
# Train the model

```{r}
model_train <- glm(loyalty ~ category, family=binomial, data=data_train)
summary(model_train)
```
# The intercept lists the effect of bakery items on whether a transaction is from a loyalty customer or not. The coefficient is positive, which means that selling a bakery item increases the likelihood that a transaction is a loyalty transaction. More precisely, purchasing this item increases the log odds of a loyalty purchase happening by 0.30575.We know now that several categories, such as fountain sodas, bakery items, and breakfast sandwiches help increase the chance a customer will be a loyalty customer. The company could promote these products to try to draw in more loyalty customers-----

# Examine accuracy with the train model first to see loyal vs non-loyal customers within regression model----

```{r}
# Predict the probabilities for each row, using a small sample of the first 10 rows to get a visual idea of model accuracy

predict_train <- predict(model_train, newdata=data_train, type='response')
print(summary(predict_train))
data_train$prediction <- predict_train
head(data_train, n=10)
```
# Determine accuracy of model using loyality and non-loyalty data----
```{r}

# Put prediction on left and truth on top
table1 <- table(predict_train>0.5, data_train$loyalty) 
my_confusion_matrix(table1)
```
# In general, the model predicts better than 50% without implementing a model, and is way better for predicting non-loyal vs loyal customers at 58%----
# Train on the testing data by replacing data_train$loyality with data_test$loyality-----

```{r}
predict_test <- predict(model_train, newdata=data_test, type='response')
print(summary(predict_test))
data_test$prediction <- predict_test
head(data_test, n=10)
table2 <- table(predict_test>.5, data_test$loyalty) #prediction on left and truth on top
my_confusion_matrix(table2)
```
# Training on the test_data is comparable to train_data in accuracy, sensitivity, and precision----

# Improve sensitivity by performing a multivariate regression to include seasons----

```{r}
model_train <- glm(loyalty ~ category + factor(quarter) + state, family=binomial, data=data_train)
summary(model_train)
```
```{r}
predict_test <- predict(model_train, newdata=data_test, type='response')
summary(predict_test)
data_test$prediction <- predict_test
head(data_test, n=10)
table2 <- table(predict_test>.5, data_test$loyalty)
my_confusion_matrix(table2)
```
# Overall, the regression model is not that great. We can improve the iterations, increase the number data or try a different model like RELU. However, with the model, the accuracy is better than 50% at 60% and by including more variables into the regression model, the sensitivty was increased from 48% to 57%----- 
